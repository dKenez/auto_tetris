{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Tetris\n",
    "## Detecting roof surfaces from satellite images with UNET architecture\n",
    "\n",
    "Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Dec  4 13:15:13 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.61.05    Driver Version: 520.61.05    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:15:00.0 Off |                    0 |\n",
      "| N/A   30C    P0    43W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:16:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    54W / 300W |   7985MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  On   | 00000000:3A:00.0 Off |                    0 |\n",
      "| N/A   35C    P0    66W / 300W |   4397MiB / 32768MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  On   | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   33C    P0    43W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    1   N/A  N/A     30306      C   python                           7982MiB |\n",
      "|    2   N/A  N/A     13513      C   python                           4394MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Check for Nvidia gpus\n",
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_augmentation import load_data, create_new_data_dirs, augment_data\n",
    "from utils import del_new_data\n",
    "# https://dev.to/rohitfarmer/how-to-run-jupyter-notebook-in-an-interactive-node-on-a-high-performance-computer-hpc-27mg\n",
    "from pathlib import Path\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/zhome/52/3/174111/auto_tetris')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_path = Path.cwd().parent\n",
    "base_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_x)=140 - len(train_y)=140\n",
      "len(val_x)=30 - len(val_y)=30\n",
      "len(test_x)=30 - len(test_y)=30\n"
     ]
    }
   ],
   "source": [
    "(train_x, train_y), (val_x, val_y), (test_x, test_y) = load_data(\n",
    "    base_path,\n",
    "    split=(70, 15, 15),\n",
    "    shuffle=True,\n",
    "    max_items=200  # how many images to create dataset from, default is all images\n",
    ")\n",
    "print(f\"{len(train_x)=} - {len(train_y)=}\")\n",
    "print(f\"{len(val_x)=} - {len(val_y)=}\")\n",
    "print(f\"{len(test_x)=} - {len(test_y)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 140/140 [00:02<00:00, 50.13it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 58.67it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 30/30 [00:00<00:00, 64.03it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create folders for the new data in project root\n",
    "del_new_data()\n",
    "create_new_data_dirs(base_path)\n",
    "\n",
    "# data augmentation\n",
    "augment_data(\n",
    "    train_x,\n",
    "    train_y,\n",
    "    base_path / \"data\",\n",
    "    base_path / \"new_data/train\",\n",
    "    augment=False,\n",
    ")\n",
    "augment_data(\n",
    "    val_x,\n",
    "    val_y,\n",
    "    base_path / \"data\",\n",
    "    base_path / \"new_data/val\",\n",
    "    augment=False\n",
    ")\n",
    "augment_data(\n",
    "    test_x,\n",
    "    test_y,\n",
    "    base_path / \"data\",\n",
    "    base_path / \"new_data/test\",\n",
    "    augment=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import seeding, create_dir, epoch_time, sort_path_list\n",
    "from Hyperparams import Hyperparams\n",
    "from data import DriveDataset\n",
    "from unet import build_unet\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeding(42)\n",
    "base_path = Path.cwd().parent\n",
    "base_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size:\n",
      "Train: 140 - Valid: 30\n"
     ]
    }
   ],
   "source": [
    "# Load train dataset\n",
    "train_x = list((base_path / \"new_data/train/images/\").glob(\"*.jpeg\"))\n",
    "train_y = list((base_path / \"new_data/train/masks/\").glob(\"*.jpeg\"))\n",
    "\n",
    "# Sort dataset, so images and masks match\n",
    "train_x.sort(key=sort_path_list)\n",
    "train_y.sort(key=sort_path_list)\n",
    "\n",
    "# Load test dataset\n",
    "val_x = list((base_path / \"new_data/val/images/\").glob(\"*.jpeg\"))\n",
    "val_y = list((base_path / \"new_data/val/masks/\").glob(\"*.jpeg\"))\n",
    "\n",
    "# Sort dataset, so images and masks match\n",
    "val_x.sort(key=sort_path_list)\n",
    "val_y.sort(key=sort_path_list)\n",
    "\n",
    "data_str = f\"Dataset size:\\nTrain: {len(train_x)} - Valid: {len(val_x)}\"\n",
    "print(data_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "create_dir(base_path / \"checkpoints\")\n",
    "checkpoint_path = base_path / \"checkpoints/checkpoint.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "getter method called\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "hyperparams = Hyperparams(base_path / \"train_conf.toml\")\n",
    "\n",
    "H = hyperparams.image_size\n",
    "W = hyperparams.image_size\n",
    "size = (H, W)\n",
    "\n",
    "batch_size = hyperparams.batch_size\n",
    "num_epochs = hyperparams.epochs\n",
    "lr = hyperparams.lr\n",
    "\n",
    "# Dataset and Dataloader\n",
    "train_dataset = DriveDataset(train_x, train_y)\n",
    "val_dataset = DriveDataset(val_x, val_y)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=2\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset, batch_size=batch_size, shuffle=False, num_workers=2\n",
    ")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = build_unet()\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "# optimizer = hyperparams.optimizer(model.parameters(), lr=hyperparams.lr)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, verbose=True)\n",
    "loss_fn = hyperparams.loss_fn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
